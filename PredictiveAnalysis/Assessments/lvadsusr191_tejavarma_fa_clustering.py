# -*- coding: utf-8 -*-
"""LVADSUSR191_TejaVarma_fa_Clustering

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GP3nvlMMKgFhTgnrBGacQ6wAWepD-ftn
"""

import numpy as np
import pandas as pd
import re
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import silhouette_score, silhouette_samples
warnings.filterwarnings('ignore')

df = pd.read_csv('https://raw.githubusercontent.com/Deepsphere-AI/LVA-Batch5-Assessment/main/customer_segmentation.csv')

df.head()

df.info()





df.describe()

df.isnull().sum() # checking null values --- 24 null values in income.

df.duplicated().sum() # checking for duplicates --- none found

# replacing null values with the median values in the given data
df['Income'] = df['Income'].fillna(df['Income'].median)

df.isnull().sum()

#dropping the object columns

df.drop(['Education','Marital_Status','Dt_Customer'], axis=1 , inplace=True)

df.info()

'''
le = LabelEncoder()
df['Education'] = le.fit_transform(df['Education'])
df['Marital_Status'] = le.fit_transform(df['Marital_Status'])
#df['Income'] = le.fit_transform(df['Income'])
df['Dt_Customer'] = le.fit_transform(df['Dt_Customer'])

df.drop(['Income'],axis=1 , inplace = True)

sns.heatmap(df.corr(),annot=True)

for col in list(df.columns):
  sns.histplot(df[col])
  plt.show()

S = MinMaxScaler()
X = S.fit_transform(df)

see = []
k_values = range(1, 11)
for k in k_values:
    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=42)
    kmeans.fit(df)
    see.append(kmeans.inertia_)

plt.figure(figsize=(16, 6))
plt.plot(k_values, see, marker='o',color='#8B4513')
plt.title('Elbow Method')
plt.xlabel('Number of Clusters (k)')
plt.ylabel('Within Cluster Sum of Squares')
plt.show()

kmeans = KMeans(n_clusters=3)
kmeans.fit(df)
cluster_labels = kmeans.labels_
df['cluster'] =  kmeans.labels_

df.head()

df.info()

plt.figure(figsize=(12,10))
sns.scatterplot(data=df, x='NumStorePurchases', y='NumWebVisitsMonth', hue='cluster', palette='viridis', s=100)
centroids = df.groupby('cluster').mean()[['NumStorePurchases', 'NumWebVisitsMonth']]
plt.scatter(centroids['NumStorePurchases'], centroids['NumWebVisitsMonth'], marker='X', color='red', s=200, label='Centroids')
plt.xlabel('NumStorePurchases')
plt.ylabel('NumWebVisitsMonth')
plt.title('Scatter plot with Cluster Centroids')
plt.legend()
plt.show()

silhouette_score(df,cluster_labels) # silhotte score is around 0.5